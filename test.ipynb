{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DTG.classes.LLM import *\n",
    "from DTG.prompts import prompt_funcs\n",
    "import json, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_INFO = 'NPC personality : lazy and shy . NPC mood : confused and amused. Convesation features : dancing, great move, tripping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dialogue_json(input_info):\n",
    "    t_0 = time.time()\n",
    "    starting_time = time.time()\n",
    "    performance_dict = {\n",
    "        'tags' : 0,\n",
    "        'abstract' : 0,\n",
    "        'endings' : 0,\n",
    "        'tree' : 0,\n",
    "        'formatted_json' : 0\n",
    "    }\n",
    "    llm = LLM()\n",
    "    print(f'Generating tags.')\n",
    "    tags_by_llm = llm.send_message_for_code(prompt_funcs.tag_prompt(input_info), model='gpt-4o-mini')\n",
    "    print(f'Tags generated in {time.time() - starting_time} seconds.')\n",
    "    performance_dict['tags'] = time.time() - starting_time\n",
    "    starting_time = time.time()\n",
    "    print(f'Generating abstract.')\n",
    "    abstract = llm.send_message_for_code(prompt_funcs.abstract_prompt(tags_by_llm, input_info))\n",
    "    print(f'Abstract generated in {time.time() - starting_time} seconds.')\n",
    "    performance_dict['abstract'] = time.time() - starting_time\n",
    "    starting_time = time.time()\n",
    "    print(f'Generating possible endings.')\n",
    "    endings_by_llm = llm.send_message_for_code(prompt_funcs.possible_ending_prompt(abstract), model='o1-mini')\n",
    "    print(f'Possible endings generated in {time.time() - starting_time} seconds.')\n",
    "    performance_dict['endings'] = time.time() - starting_time\n",
    "    starting_time = time.time()\n",
    "    print(f'Generating dialogue tree.')\n",
    "    tree_by_llm = llm.send_message_for_code(prompt_funcs.dialogue_prompt(abstract, endings_by_llm, tags_by_llm), model='o1-preview')\n",
    "    print(f'Dialogue tree generated in {time.time() - starting_time} seconds.')\n",
    "    performance_dict['tree'] = time.time() - starting_time\n",
    "    starting_time = time.time()\n",
    "    print(f'Formatting JSON.')\n",
    "    formatted_tree = llm.send_message(prompt_funcs.format_prompt(tree_by_llm), model='gpt-4o-mini')\n",
    "    print(f'JSON formatted in {time.time() - starting_time} seconds.')\n",
    "    performance_dict['formatted_json'] = time.time() - starting_time\n",
    "    starting_time = time.time()\n",
    "    print(f'Total time taken : {time.time() - t_0} seconds.')\n",
    "    print(f'Performance dict : {performance_dict}')\n",
    "    formatted_tree_json = json.loads(formatted_tree)\n",
    "    #formatted_endings_json = json.loads(endings_by_llm)\n",
    "    return formatted_tree_json, endings_by_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree, endings = get_dialogue_json(INPUT_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DTG.classes.OutputClasses import Tree, PossibleEndings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dialogue_json(input_info):\n",
    "    t_0 = time.time()\n",
    "    starting_time = time.time()\n",
    "    performance_dict = {\n",
    "        'tags' : 0,\n",
    "        'abstract' : 0,\n",
    "        'endings' : 0,\n",
    "        'tree' : 0\n",
    "    }\n",
    "    llm = LLM()\n",
    "    print(f'Generating tags.')\n",
    "    tags_by_llm = llm.send_message_for_code(prompt_funcs.tag_prompt(input_info), model='gpt-4o-mini')\n",
    "    print(f'Tags generated in {time.time() - starting_time} seconds.')\n",
    "    performance_dict['tags'] = time.time() - starting_time\n",
    "    starting_time = time.time()\n",
    "    print(f'Generating abstract.')\n",
    "    abstract = llm.send_message_for_code(prompt_funcs.abstract_prompt(tags_by_llm, input_info))\n",
    "    print(f'Abstract generated in {time.time() - starting_time} seconds.')\n",
    "    performance_dict['abstract'] = time.time() - starting_time\n",
    "    starting_time = time.time()\n",
    "    print(f'Generating possible endings.')\n",
    "    endings_by_llm = llm.send_message_for_format(prompt_funcs.possible_ending_prompt(abstract), PossibleEndings ,model='gpt-4o')\n",
    "    print(f'Possible endings generated in {time.time() - starting_time} seconds.')\n",
    "    performance_dict['endings'] = time.time() - starting_time\n",
    "    starting_time = time.time()\n",
    "    print(f'Generating dialogue tree.')\n",
    "    tree_by_llm = llm.send_message_for_format(prompt_funcs.dialogue_prompt(abstract, endings_by_llm, tags_by_llm), format=Tree,model='gpt-4o')\n",
    "    print(f'Dialogue tree generated in {time.time() - starting_time} seconds.')\n",
    "    performance_dict['tree'] = time.time() - starting_time\n",
    "    starting_time = time.time()\n",
    "    print(f'Total time taken : {time.time() - t_0} seconds.')\n",
    "    print(f'Performance dict : {performance_dict}')\n",
    "    #formatted_endings_json = json.loads(endings_by_llm)\n",
    "    return tree_by_llm, endings_by_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tags.\n",
      "Tags generated in 2.6880886554718018 seconds.\n",
      "Generating abstract.\n",
      "Abstract generated in 3.8903868198394775 seconds.\n",
      "Generating possible endings.\n",
      "Possible endings generated in 4.215151071548462 seconds.\n",
      "Generating dialogue tree.\n",
      "Dialogue tree generated in 24.871508836746216 seconds.\n",
      "Total time taken : 35.665934801101685 seconds.\n",
      "Performance dict : {'tags': 2.688295841217041, 'abstract': 3.890544891357422, 'endings': 4.2153661251068115, 'tree': 24.8717200756073}\n"
     ]
    }
   ],
   "source": [
    "tree, endings = get_dialogue_json(INPUT_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json', 'w') as file:\n",
    "    json.dump(json.loads(tree), file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
